R version 4.3.3 (2024-02-29 ucrt) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R jest oprogramowaniem darmowym i dostarczany jest BEZ JAKIEJKOLWIEK GWARANCJI.
Możesz go rozpowszechniać pod pewnymi warunkami.
Wpisz 'license()' lub 'licence()' aby uzyskać szczegóły dystrybucji.

R jest projektem kolaboracyjnym z wieloma uczestnikami.
Wpisz 'contributors()' aby uzyskać więcej informacji oraz
'citation()' aby dowiedzieć się jak cytować R lub pakiety R w publikacjach.

Wpisz 'demo()' aby zobaczyć demo, 'help()' aby uzyskać pomoc on-line, lub
'help.start()' aby uzyskać pomoc w przeglądarce HTML.
Wpisz 'q()' aby wyjść z R.

> setwd("C:/Users/mrbre/Desktop/Studia/APU/Lab6")
> install.packages(pkgs=c("tm", "SnowballC", "wordcloud", "RColorBrewer", "syuzhet", "ggplot2"))
Instalowanie pakietów w ‘C:/Users/mrbre/AppData/Local/R/win-library/4.3’
(ponieważ ‘lib’ nie jest określony)
instalowanie dodatkowych zależności ‘NLP’, ‘slam’, ‘BH’, ‘textshape’, ‘dtt’

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/NLP_0.2-1.zip'
Content type 'application/zip' length 389611 bytes (380 KB)
downloaded 380 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/slam_0.1-50.zip'
Content type 'application/zip' length 189475 bytes (185 KB)
downloaded 185 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/BH_1.84.0-0.zip'
Content type 'application/zip' length 21468566 bytes (20.5 MB)
downloaded 20.5 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/textshape_1.7.5.zip'
Content type 'application/zip' length 519899 bytes (507 KB)
downloaded 507 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/dtt_0.1-2.zip'
Content type 'application/zip' length 21696 bytes (21 KB)
downloaded 21 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/tm_0.7-13.zip'
Content type 'application/zip' length 998978 bytes (975 KB)
downloaded 975 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/SnowballC_0.7.1.zip'
Content type 'application/zip' length 364431 bytes (355 KB)
downloaded 355 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/wordcloud_2.6.zip'
Content type 'application/zip' length 447461 bytes (436 KB)
downloaded 436 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/RColorBrewer_1.1-3.zip'
Content type 'application/zip' length 56066 bytes (54 KB)
downloaded 54 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/syuzhet_1.0.7.zip'
Content type 'application/zip' length 3109576 bytes (3.0 MB)
downloaded 3.0 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/ggplot2_3.5.1.zip'
Content type 'application/zip' length 4954381 bytes (4.7 MB)
downloaded 4.7 MB

pakiet ‘NLP’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘slam’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘BH’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘textshape’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘dtt’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘tm’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘SnowballC’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘wordcloud’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘RColorBrewer’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘syuzhet’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘ggplot2’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone

Pobrane pakiety binarne są w
	C:\Users\mrbre\AppData\Local\Temp\RtmpKQ9aX0\downloaded_packages
> library("tm")
Ładowanie wymaganego pakietu: NLP
> library("SnowballC")
> library("wordcloud")
Ładowanie wymaganego pakietu: RColorBrewer
> library("RColorBrewer")
> library("syuzhet")
> library("ggplot2")
Need help getting started? Try the R Graphics Cookbook: https://r-graphics.org

Dołączanie pakietu: ‘ggplot2’

Następujący obiekt został zakryty z ‘package:NLP’:

    annotate

> text <- readLines("machine_learning_wiki.txt")
Komunikat ostrzegawczy:
W poleceniu 'readLines("machine_learning_wiki.txt")':
  niekompletna końcowa linia znaleziona w 'machine_learning_wiki.txt'
> text <- readLines("Machine_learning_wiki.txt")
Komunikat ostrzegawczy:
W poleceniu 'readLines("Machine_learning_wiki.txt")':
  niekompletna końcowa linia znaleziona w 'Machine_learning_wiki.txt'
> TextDoc <- Corpus(VectorSource(text))
> toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
> TextDoc <- tm_map(TextDoc, toSpace, "/")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, "/")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, "@")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, "@")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, "\\|")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, "\\|")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, "ˆa“")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, "ˆa“")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, ":")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, ":")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, ";")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, ";")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, toSpace, ",")
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, toSpace, ",")':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, content_transformer(tolower))
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, content_transformer(tolower))':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, removeNumbers)
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, removeNumbers)':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, removeWords, stopwords("english"))':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, removeWords, c("s", "company", "team"))
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, removeWords, c("s", "company", "team"))':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, removePunctuation)
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, removePunctuation)':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, stripWhitespace)
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, stripWhitespace)':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, stemDocument)
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, stemDocument)':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, content_transformer(
+     function(x) gsub(x, pattern = "mathemat", replacement = "math")))
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, content_transformer(function(x) gsub(x, ':
  transformation drops documents
> TextDoc <- tm_map(TextDoc, content_transformer(
+     function(x) gsub(x, pattern = " r ", replacement = " Rlanguage ")))
Komunikat ostrzegawczy:
W poleceniu 'tm_map.SimpleCorpus(TextDoc, content_transformer(function(x) gsub(x, ':
  transformation drops documents
> TextDoc_dtm <- TermDocumentMatrix(TextDoc)
> dtm_m <- as.matrix(TextDoc_dtm)
> dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
> dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
> head(dtm_d, 5)
               word freq
learn         learn  270
machin       machin  148
data           data  119
model         model   90
algorithm algorithm   82
> barplot(dtm_d[1:20,]$freq, las = 2, names.arg = dtm_d[1:20,]$word,
+         col ="lightgreen",
+         main ="20 najczestszych wystepujacych slow w artykule wiki Machine learning",
+         ylab = "Czestotliwosc slow")
> set.seed(1234)
> wordcloud(words = dtm_d$word, freq = dtm_d$freq, scale=c(5,0.5),
+           min.freq = 1,
+           max.words=100, random.order=FALSE,
+           rot.per=0.40,
+           colors=brewer.pal(8, "Dark2"))
> findAssocs(TextDoc_dtm, terms = findFreqTerms(TextDoc_dtm, lowfreq = 30),
+            corlimit = 0.5)
$learn
numeric(0)

$machin
team 
 0.5 

$data
numeric(0)

$predict
           art         artist          award           chao      cinematch        cofound       collabor 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
      competit          covid          crisi           cure         doctor        everyth            far 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
          fine          grand           held          joint         khosla   labsresearch           lost 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
   mediaservic    microsystem        million           mlas           movi        netflix           next 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
         paint        pragmat         prefer proenvironment         realiz      rebellion         return 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
         short      smartphon       springer         street            sun        thermal       unrecogn 
          0.58           0.58           0.58           0.58           0.58           0.58           0.58 
        viewer          vinod           wall          wrote          stock           team           firm 
          0.58           0.58           0.58           0.58           0.57           0.57           0.57 
         prize          appli      recommend         recent      technolog 
          0.54           0.52           0.52           0.51           0.51 

$artifici
   neuron     cross      last     layer      loos   proceed      sent  strength       sum threshold  transmit 
     0.89      0.84      0.84      0.84      0.84      0.84      0.84      0.84      0.84      0.84      0.84 
  travers   connect    signal     brain    weight    aggreg       ann    biolog       edg    travel      node 
     0.84      0.83      0.82      0.77      0.75      0.75      0.75      0.75      0.75      0.59      0.58 
  multipl     anoth    synaps 
     0.53      0.52      0.52 

$network
      acycl         dag     diagram      diseas     protein     symptom     graphic    bayesian probabilist 
       0.71        0.71        0.71        0.71        0.71        0.71        0.66        0.66        0.60 
     neural    independ      direct        solv 
       0.59        0.57        0.53        0.52 

$model
fulli 
 0.53 

$algorithm
numeric(0)

$can
class 
 0.52 

$perform
numeric(0)

$comput
numeric(0)

$method
 communiti     confus     easili       hand    overlap   reproduc    unavail   uninform    respect      evalu 
      0.66       0.66       0.66       0.66       0.66       0.66       0.66       0.66       0.65       0.65 
 discoveri        kdd       step        key   knowledg outperform       much       mine      focus   properti 
      0.60       0.59       0.59       0.56       0.55       0.54       0.54       0.53       0.53       0.53 
     separ    unknown      known 
      0.53       0.53       0.52 

$process
numeric(0)

$use
numeric(0)

$set
   instanc       test     involv   techniqu     abnorm  construct      inher likelihood    remaind       seem 
      0.65       0.62       0.60       0.54       0.53       0.53       0.53       0.53       0.53       0.53 
  unbalanc     normal 
      0.53       0.51 

$system
numeric(0)

$train
numeric(0)

$featur
autoencod  multilay    altern    examin 
     0.54      0.54      0.53      0.53 

$input
output  desir 
  0.67   0.60 

$exampl
numeric(0)

> syuzhet_vector <- get_sentiment(text, method="syuzhet")
> head(syuzhet_vector)
[1] 0.8 0.0 0.0 0.4 0.0 0.0
> summary(syuzhet_vector)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-3.7500  0.0000  0.0000  0.5193  0.7625 12.9000 
> bing_vector <- get_sentiment(text, method="bing")
> head(bing_vector)
[1] 0 0 0 0 0 0
> summary(bing_vector)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 -9.000   0.000   0.000   0.032   0.000  11.000 
> afinn_vector <- get_sentiment(text, method="afinn")
> head(afinn_vector)
[1] 0 0 0 0 0 0
> summary(afinn_vector)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-11.000   0.000   0.000   0.204   0.000  16.000 
> rbind(
+     sign(head(syuzhet_vector)),
+     sign(head(bing_vector)),
+     sign(head(afinn_vector))
+ )
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    0    0    1    0    0
[2,]    0    0    0    0    0    0
[3,]    0    0    0    0    0    0
> d<-get_nrc_sentiment(as.vector(dtm_d$word)) # Analiza trwa bardzo dlugo
> head (d,10)
   anger anticipation disgust fear joy sadness surprise trust negative positive
1      0            0       0    0   0       0        0     0        0        1
2      0            0       0    0   0       0        0     0        0        0
3      0            0       0    0   0       0        0     0        0        0
4      0            0       0    0   0       0        0     0        0        1
5      0            0       0    0   0       0        0     0        0        0
6      0            0       0    0   0       0        0     0        0        0
7      0            0       0    0   0       0        0     0        0        0
8      0            0       0    0   0       0        0     0        0        0
9      0            0       0    0   0       0        0     0        0        0
10     0            0       0    0   0       0        0     0        0        0
> syuzhet_vector <- get_sentiment(text, method="syuzhet")
> head(syuzhet_vector)
[1] 0.8 0.0 0.0 0.4 0.0 0.0
> summary(syuzhet_vector)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-3.7500  0.0000  0.0000  0.5193  0.7625 12.9000 
> td<-data.frame(t(d))
> td_new <- data.frame(rowSums(td[1:56]))
> names(td_new)[1] <- "count"
> td_new <- cbind("sentiment" = rownames(td_new), td_new)
> rownames(td_new) <- NULL
> td_new2<-td_new[1:8,]
> quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment,
+           ylab="count")+ggtitle("Survey sentiments")
Komunikat ostrzegawczy:
`qplot()` was deprecated in ggplot2 3.4.0.
This warning is displayed once every 8 hours.
Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 
> barplot(
+     sort(colSums(prop.table(d[, 1:8]))),
+     horiz = TRUE,
+     cex.names = 0.7,
+     las = 1,
+     main = "Emotions in Text", xlab="Percentage"
+ )
> install.packages(pkgs=c("tidytext", "igraph", "ggraph"))
Instalowanie pakietów w ‘C:/Users/mrbre/AppData/Local/R/win-library/4.3’
(ponieważ ‘lib’ nie jest określony)
instalowanie dodatkowych zależności ‘tweenr’, ‘polyclip’, ‘RcppEigen’, ‘RcppArmadillo’, ‘janeaustenr’, ‘tokenizers’, ‘ggforce’, ‘ggrepel’, ‘viridis’, ‘tidygraph’, ‘graphlayouts’

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/tweenr_2.0.3.zip'
Content type 'application/zip' length 538250 bytes (525 KB)
downloaded 525 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/polyclip_1.10-6.zip'
Content type 'application/zip' length 396925 bytes (387 KB)
downloaded 387 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/RcppEigen_0.3.4.0.0.zip'
Content type 'application/zip' length 2611019 bytes (2.5 MB)
downloaded 2.5 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/RcppArmadillo_0.12.8.3.0.zip'
Content type 'application/zip' length 2052018 bytes (2.0 MB)
downloaded 2.0 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/janeaustenr_1.0.0.zip'
Content type 'application/zip' length 1626348 bytes (1.6 MB)
downloaded 1.6 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/tokenizers_0.3.0.zip'
Content type 'application/zip' length 985784 bytes (962 KB)
downloaded 962 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/ggforce_0.4.2.zip'
Content type 'application/zip' length 2178737 bytes (2.1 MB)
downloaded 2.1 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/ggrepel_0.9.5.zip'
Content type 'application/zip' length 617123 bytes (602 KB)
downloaded 602 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/viridis_0.6.5.zip'
Content type 'application/zip' length 3015481 bytes (2.9 MB)
downloaded 2.9 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/tidygraph_1.3.1.zip'
Content type 'application/zip' length 637876 bytes (622 KB)
downloaded 622 KB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/graphlayouts_1.1.1.zip'
Content type 'application/zip' length 4127260 bytes (3.9 MB)
downloaded 3.9 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/tidytext_0.4.2.zip'
Content type 'application/zip' length 3014574 bytes (2.9 MB)
downloaded 2.9 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/igraph_2.0.3.zip'
Content type 'application/zip' length 7260662 bytes (6.9 MB)
downloaded 6.9 MB

próbowanie adresu URL 'https://cran.rstudio.com/bin/windows/contrib/4.3/ggraph_2.2.1.zip'
Content type 'application/zip' length 4578990 bytes (4.4 MB)
downloaded 4.4 MB

pakiet ‘tweenr’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘polyclip’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘RcppEigen’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘RcppArmadillo’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘janeaustenr’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘tokenizers’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘ggforce’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘ggrepel’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘viridis’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘tidygraph’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘graphlayouts’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘tidytext’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘igraph’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone
pakiet ‘ggraph’ został pomyślnie rozpakowany oraz sumy MD5 zostały sprawdzone

Pobrane pakiety binarne są w
	C:\Users\mrbre\AppData\Local\Temp\RtmpKQ9aX0\downloaded_packages
> library("tidytext")
> library("igraph")

Dołączanie pakietu: ‘igraph’

Następujące obiekty zostały zakryte z ‘package:stats’:

    decompose, spectrum

Następujący obiekt został zakryty z ‘package:base’:

    union

> library("ggraph")
> ileName <- "Machine_learning_wiki.txt"
> text <- readChar(fileName, file.info(fileName)$size)
BŁĄD: nie znaleziono obiektu 'fileName'
> fileName <- "Machine_learning_wiki.txt"
> text <- readChar(fileName, file.info(fileName)$size)
> library(dplyr)

Dołączanie pakietu: ‘dplyr’

Następujące obiekty zostały zakryte z ‘package:igraph’:

    as_data_frame, groups, union

Następujące obiekty zostały zakryte z ‘package:stats’:

    filter, lag

Następujące obiekty zostały zakryte z ‘package:base’:

    intersect, setdiff, setequal, union

> text_df <- data_frame(line = 1, text = text)
Komunikat ostrzegawczy:
`data_frame()` was deprecated in tibble 1.1.0.
ℹ Please use `tibble()` instead.
This warning is displayed once every 8 hours.
Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 
> text_df
# A tibble: 1 × 2
   line text                                                                                                      
  <dbl> <chr>                                                                                                     
1     1 "Machine learning\r\n\r\nArticle\r\nTalk\r\nRead\r\nEdit\r\nView history\r\n\r\nTools\r\nFrom Wikipedia, …
> library(tidytext)
> tidy_text <- text_df %>%
+     unnest_tokens(word, text)
> data(stop_words)
> stop_words <- rbind(stop_words,de)
Błąd w poleceniu 'rep_len(xi, nvar)':próba powielenia nie-wektora
> fileName <- "Machine_learning_wiki.txt"
> text <- readChar(fileName, file.info(fileName)$size)
> library(dplyr)
> text_df <- data_frame(line = 1, text = text)
> text_df
# A tibble: 1 × 2
   line text                                                                                                      
  <dbl> <chr>                                                                                                     
1     1 "Machine learning\r\n\r\nArticle\r\nTalk\r\nRead\r\nEdit\r\nView history\r\n\r\nTools\r\nFrom Wikipedia, …
> library(tidytext)
> tidy_text <- text_df %>%
+     unnest_tokens(word, text)
> data(stop_words)
> stop_words <- rbind(stop_words,de)
Błąd w poleceniu 'rep_len(xi, nvar)':próba powielenia nie-wektora
> fileName <- "Machine_learning_wiki.txt"
> text <- readChar(fileName, file.info(fileName)$size)
> library(dplyr)
> text_df <- data_frame(line = 1, text = text)
> library(tidytext)
> tidy_text <- text_df %>%
+ unnest_tokens(word, text)
> data(stop_words)
> stop_words <- rbind(stop_words,de)
Błąd w poleceniu 'rep_len(xi, nvar)':próba powielenia nie-wektora
> data(stop_words)
> de <- data.frame("thy", "OLD_WORDS")
> names(de) <- c("word", "lexicon")
> stop_words <- rbind(stop_words, de)
> de <- data.frame("1", "OLD_WORDS")
> names(de) <- c("word", "lexicon")
> de <- data.frame("hath", "OLD_WORDS")
> names(de) <- c("word", "lexicon")
> de <- data.frame("mar'd", "OLD_WORDS")
> names(de) <- c("word", "lexicon")
> stop_words <- rbind(stop_words, de)
> 
> tidy_text <- tidy_text %>%
+     anti_join(stop_words)
Joining with `by = join_by(word)`
> tidy_text %>%
+     count(word, sort = TRUE)
# A tibble: 2,139 × 2
   word           n
   <chr>      <int>
 1 learning     257
 2 machine      145
 3 data         120
 4 model         52
 5 algorithms    47
 6 training      47
 7 artificial    40
 8 set           34
 9 models        31
10 ai            29
# ℹ 2,129 more rows
# ℹ Use `print(n = ...)` to see more rows
> text_bigrams <- text_df %>%
+     unnest_tokens(
+         bigram, 
+         text, 
+         token = "ngrams", 
+         n = 2)
> text_bigrams
# A tibble: 9,537 × 2
    line bigram          
   <dbl> <chr>           
 1     1 machine learning
 2     1 learning article
 3     1 article talk    
 4     1 talk read       
 5     1 read edit       
 6     1 edit view       
 7     1 view history    
 8     1 history tools   
 9     1 tools from      
10     1 from wikipedia  
# ℹ 9,527 more rows
# ℹ Use `print(n = ...)` to see more rows
> text_bigrams %>%
+     count(bigram, sort = TRUE)
# A tibble: 7,275 × 2
   bigram                  n
   <chr>               <int>
 1 machine learning      131
 2 of the                 45
 3 in the                 32
 4 is a                   27
 5 learning algorithms    26
 6 can be                 24
 7 main article           20
 8 of a                   20
 9 as a                   17
10 of machine             17
# ℹ 7,265 more rows
# ℹ Use `print(n = ...)` to see more rows
> library(tidyr)

Dołączanie pakietu: ‘tidyr’

Następujący obiekt został zakryty z ‘package:igraph’:

    crossing

> bigrams_separated <- text_bigrams %>%
+     separate(bigram, c("word1", "word2"), sep = " ")
> bigrams_filtered <- bigrams_separated %>%
+ filter(!word1 %in% stop_words$word) %>%
+     filter(!word2 %in% stop_words$word)
> bigram_counts <- bigrams_filtered %>%
+     count(word1, word2, sort = TRUE)
> bigram_counts
# A tibble: 2,375 × 3
   word1         word2            n
   <chr>         <chr>        <int>
 1 machine       learning       131
 2 learning      algorithms      26
 3 main          article         20
 4 supervised    learning        17
 5 data          mining          13
 6 neural        networks        13
 7 artificial    intelligence    12
 8 artificial    neural          12
 9 reinforcement learning        11
10 training      data            11
# ℹ 2,365 more rows
# ℹ Use `print(n = ...)` to see more rows
> 
> bigrams_united <- bigrams_filtered %>%
+     unite(bigram, word1, word2, sep = " ")
> bigrams_united
# A tibble: 3,001 × 2
    line bigram           
   <dbl> <chr>            
 1     1 machine learning 
 2     1 learning article 
 3     1 article talk     
 4     1 talk read        
 5     1 read edit        
 6     1 edit view        
 7     1 view history     
 8     1 history tools    
 9     1 free encyclopedia
10     1 machine learning 
# ℹ 2,991 more rows
# ℹ Use `print(n = ...)` to see more rows